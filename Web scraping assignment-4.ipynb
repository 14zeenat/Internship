{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6dc46d4",
   "metadata": {},
   "source": [
    "### ASSIGNMENT-4\n",
    "### WEB SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0693d4c",
   "metadata": {},
   "source": [
    "#### • Read all the problem statements, notes carefully and scrape the required data using any web scraping tool of your choice.\n",
    "#### • You have to handle commonly occurring EXCEPTIONS by using exception handling programing. To get information about selenium Exceptions. You may visit following links:\n",
    "1. https://selenium-python.readthedocs.io/api.html\n",
    "2. https://www.guru99.com/exception-handling-selenium.html\n",
    "3. https://stackoverflow.com/questions/38022658/selenium-python-handling-no-such-element-exception/380233"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa54e95",
   "metadata": {},
   "source": [
    "##### 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos                                                          \n",
    "You need to find following details:                                                                                            \n",
    "A) Rank                                                                                                                        \n",
    "B) Name                                                                                                                        \n",
    "C) Artist                                                                                                                       \n",
    "D) Upload date                                                                                                              \n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0c6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ff12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"Z:\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b2507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the page on automated chrome browser\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85173483",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b9d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "rank = []\n",
    "name = []\n",
    "artist = []\n",
    "upload_date = []\n",
    "views = []\n",
    "\n",
    "# scraping and storing data\n",
    "rows = driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div/table[2]/tbody/tr')\n",
    "for r in rows:\n",
    "    \n",
    "    # scraping rank\n",
    "    rank_tags = r.find_element(By.XPATH,\"td[1]\").text\n",
    "    rank.append(rank_tags)\n",
    "    \n",
    "    # scraping name\n",
    "    name_tags = r.find_element(By.XPATH,\"td[2]\").text\n",
    "    name.append(name_tags.split('\"')[1])\n",
    "    \n",
    "    # scraping artist\n",
    "    artist_tags = r.find_element(By.XPATH,\"td[3]\").text\n",
    "    artist.append(artist_tags)\n",
    "    \n",
    "    # scraping upload date\n",
    "    date = r.find_element(By.XPATH,\"td[5]\").text\n",
    "    upload_date.append(date)\n",
    "    \n",
    "    # scraping views\n",
    "    view_tags = r.find_element(By.XPATH,\"td[4]\").text\n",
    "    views.append(view_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e5b1a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),len(name),len(artist),len(upload_date),len(views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c57fd5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe\n",
    "videos = pd.DataFrame({'Rank':rank,'Name':name,'Artist':artist,'Upload date':upload_date,'Views':views})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5605f0cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                                  Bath Song   \n",
       "4    5.                               Shape of You   \n",
       "5    6.                              See You Again   \n",
       "6    7.                Phonics Song with Two Words   \n",
       "7    8.                          Wheels on the Bus   \n",
       "8    9.                                Uptown Funk   \n",
       "9   10.  Learning Colors – Colorful Eggs on a Farm   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.   Masha and the Bear – Recipe for Disaster   \n",
       "12  13.                             Dame Tu Cosita   \n",
       "13  14.                                     Axel F   \n",
       "14  15.                                      Sugar   \n",
       "15  16.                                       Roar   \n",
       "16  17.                             Counting Stars   \n",
       "17  18.                                      Sorry   \n",
       "18  19.                        Baa Baa Black Sheep   \n",
       "19  20.                          Thinking Out Loud   \n",
       "20  21.           Waka Waka (This Time for Africa)   \n",
       "21  22.                                 Dark Horse   \n",
       "22  23.                                      Faded   \n",
       "23  24.                                    Perfect   \n",
       "24  25.                             Lakdi Ki Kathi   \n",
       "25  26.                                 Let Her Go   \n",
       "26  27.                             Girls Like You   \n",
       "27  28.          Humpty the train on a fruits ride   \n",
       "28  29.                                    Lean On   \n",
       "29  30.                                   Bailando   \n",
       "\n",
       "                                           Artist        Upload date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  12.73  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.14  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.69  \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   6.15  \n",
       "4                                      Ed Sheeran   January 30, 2017   5.97  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.86  \n",
       "6                                       ChuChu TV      March 6, 2014   5.26  \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   5.14  \n",
       "8                                     Mark Ronson  November 19, 2014   4.89  \n",
       "9                                     Miroshka TV  February 27, 2018   4.87  \n",
       "10                                            Psy      July 15, 2012   4.77  \n",
       "11                                     Get Movies   January 31, 2012   4.55  \n",
       "12                                      El Chombo      April 5, 2018   4.32  \n",
       "13                                     Crazy Frog      June 16, 2009   3.87  \n",
       "14                                       Maroon 5   January 14, 2015   3.86  \n",
       "15                                     Katy Perry  September 5, 2013   3.78  \n",
       "16                                    OneRepublic       May 31, 2013   3.77  \n",
       "17                                  Justin Bieber   October 22, 2015   3.65  \n",
       "18                     Cocomelon – Nursery Rhymes      June 25, 2018   3.61  \n",
       "19                                     Ed Sheeran    October 7, 2014   3.58  \n",
       "20                                        Shakira       June 4, 2010   3.56  \n",
       "21                                     Katy Perry  February 20, 2014   3.50  \n",
       "22                                    Alan Walker   December 3, 2015   3.44  \n",
       "23                                     Ed Sheeran   November 9, 2017   3.42  \n",
       "24                                   Jingle Toons      June 14, 2018   3.42  \n",
       "25                                      Passenger      July 25, 2012   3.42  \n",
       "26                                       Maroon 5       May 31, 2018   3.40  \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.38  \n",
       "28                                    Major Lazer     March 22, 2015   3.37  \n",
       "29                               Enrique Iglesias     April 11, 2014   3.37  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff3bf185",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df732663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f2125b3",
   "metadata": {},
   "source": [
    "##### 2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/                                                                                                     \n",
    "You need to find following details:                                                                                  \n",
    "A) Match title (I.e. 1stODI)                                                                                          \n",
    "B) Series                                                                                                                       \n",
    "C) Place                                                                                                              \n",
    "D) Date                                                                                                                     \n",
    "E) Time                                                                                                  \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40dbe8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b9a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"Z:\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc4b0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the page on automated chrome browser\n",
    "driver.get(\" https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3849dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cc302b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on international\n",
    "international = driver.find_element(By.XPATH,'//ul[@class=\"nav navbar-nav  align-items-center\"]/li[2]/a')\n",
    "international.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa00aaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception raised: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".matchOrderText ng-binding ng-scope\"}\n",
      "  (Session info: chrome=112.0.5615.138)\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\tGetHandleVerifier [0x0060DCE3+50899]\n",
      "\t(No symbol) [0x0059E111]\n",
      "\t(No symbol) [0x004A5588]\n",
      "\t(No symbol) [0x004D08F9]\n",
      "\t(No symbol) [0x004D0AFB]\n",
      "\t(No symbol) [0x004FF902]\n",
      "\t(No symbol) [0x004EB944]\n",
      "\t(No symbol) [0x004FE01C]\n",
      "\t(No symbol) [0x004EB6F6]\n",
      "\t(No symbol) [0x004C7708]\n",
      "\t(No symbol) [0x004C886D]\n",
      "\tGetHandleVerifier [0x00873EAE+2566302]\n",
      "\tGetHandleVerifier [0x008A92B1+2784417]\n",
      "\tGetHandleVerifier [0x008A327C+2759788]\n",
      "\tGetHandleVerifier [0x006A5740+672048]\n",
      "\t(No symbol) [0x005A8872]\n",
      "\t(No symbol) [0x005A41C8]\n",
      "\t(No symbol) [0x005A42AB]\n",
      "\t(No symbol) [0x005971B7]\n",
      "\tBaseThreadInitThunk [0x76C57D49+25]\n",
      "\tRtlInitializeExceptionChain [0x777BB74B+107]\n",
      "\tRtlClearBits [0x777BB6CF+191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scraping match title\n",
    "try:\n",
    "    match_title = driver.find_element(By.CLASS_NAME,\"matchOrderText ng-binding ng-scope\").text.split(\" -\")[0]\n",
    "except NoSuchElementException as e:\n",
    "    print('Exception raised:',e)\n",
    "    match_title = driver.find_element(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]').text.split(\" -\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a799dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Final'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b8be5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception raised: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".match-tournament-name ng-binding\"}\n",
      "  (Session info: chrome=112.0.5615.138)\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\tGetHandleVerifier [0x0060DCE3+50899]\n",
      "\t(No symbol) [0x0059E111]\n",
      "\t(No symbol) [0x004A5588]\n",
      "\t(No symbol) [0x004D08F9]\n",
      "\t(No symbol) [0x004D0AFB]\n",
      "\t(No symbol) [0x004FF902]\n",
      "\t(No symbol) [0x004EB944]\n",
      "\t(No symbol) [0x004FE01C]\n",
      "\t(No symbol) [0x004EB6F6]\n",
      "\t(No symbol) [0x004C7708]\n",
      "\t(No symbol) [0x004C886D]\n",
      "\tGetHandleVerifier [0x00873EAE+2566302]\n",
      "\tGetHandleVerifier [0x008A92B1+2784417]\n",
      "\tGetHandleVerifier [0x008A327C+2759788]\n",
      "\tGetHandleVerifier [0x006A5740+672048]\n",
      "\t(No symbol) [0x005A8872]\n",
      "\t(No symbol) [0x005A41C8]\n",
      "\t(No symbol) [0x005A42AB]\n",
      "\t(No symbol) [0x005971B7]\n",
      "\tBaseThreadInitThunk [0x76C57D49+25]\n",
      "\tRtlInitializeExceptionChain [0x777BB74B+107]\n",
      "\tRtlClearBits [0x777BB6CF+191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scraping series\n",
    "try:\n",
    "    series = driver.find_element(By.CLASS_NAME,\"match-tournament-name ng-binding\").text\n",
    "except NoSuchElementException as e:\n",
    "    print('Exception raised:',e)\n",
    "    series = driver.find_element(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4c6bf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ICC WORLD TEST CHAMPIONSHIP FINAL 2023'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3018c7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception raised: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".match-place ng-scope\"}\n",
      "  (Session info: chrome=112.0.5615.138)\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\tGetHandleVerifier [0x0060DCE3+50899]\n",
      "\t(No symbol) [0x0059E111]\n",
      "\t(No symbol) [0x004A5588]\n",
      "\t(No symbol) [0x004D08F9]\n",
      "\t(No symbol) [0x004D0AFB]\n",
      "\t(No symbol) [0x004FF902]\n",
      "\t(No symbol) [0x004EB944]\n",
      "\t(No symbol) [0x004FE01C]\n",
      "\t(No symbol) [0x004EB6F6]\n",
      "\t(No symbol) [0x004C7708]\n",
      "\t(No symbol) [0x004C886D]\n",
      "\tGetHandleVerifier [0x00873EAE+2566302]\n",
      "\tGetHandleVerifier [0x008A92B1+2784417]\n",
      "\tGetHandleVerifier [0x008A327C+2759788]\n",
      "\tGetHandleVerifier [0x006A5740+672048]\n",
      "\t(No symbol) [0x005A8872]\n",
      "\t(No symbol) [0x005A41C8]\n",
      "\t(No symbol) [0x005A42AB]\n",
      "\t(No symbol) [0x005971B7]\n",
      "\tBaseThreadInitThunk [0x76C57D49+25]\n",
      "\tRtlInitializeExceptionChain [0x777BB74B+107]\n",
      "\tRtlClearBits [0x777BB6CF+191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scraping place\n",
    "try:\n",
    "    place = driver.find_element(By.CLASS_NAME,\"match-place ng-scope\").text.split(\" - \")[1]\n",
    "except NoSuchElementException as e:\n",
    "    print('Exception raised:',e)\n",
    "    place = driver.find_element(By.XPATH,'//div[@class=\"match-place ng-scope\"]').text.split(\" - \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8aac54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kennington Oval, London'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b6d940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception raised: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".match-dates ng-binding\"}\n",
      "  (Session info: chrome=112.0.5615.138)\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\tGetHandleVerifier [0x0060DCE3+50899]\n",
      "\t(No symbol) [0x0059E111]\n",
      "\t(No symbol) [0x004A5588]\n",
      "\t(No symbol) [0x004D08F9]\n",
      "\t(No symbol) [0x004D0AFB]\n",
      "\t(No symbol) [0x004FF902]\n",
      "\t(No symbol) [0x004EB944]\n",
      "\t(No symbol) [0x004FE01C]\n",
      "\t(No symbol) [0x004EB6F6]\n",
      "\t(No symbol) [0x004C7708]\n",
      "\t(No symbol) [0x004C886D]\n",
      "\tGetHandleVerifier [0x00873EAE+2566302]\n",
      "\tGetHandleVerifier [0x008A92B1+2784417]\n",
      "\tGetHandleVerifier [0x008A327C+2759788]\n",
      "\tGetHandleVerifier [0x006A5740+672048]\n",
      "\t(No symbol) [0x005A8872]\n",
      "\t(No symbol) [0x005A41C8]\n",
      "\t(No symbol) [0x005A42AB]\n",
      "\t(No symbol) [0x005971B7]\n",
      "\tBaseThreadInitThunk [0x76C57D49+25]\n",
      "\tRtlInitializeExceptionChain [0x777BB74B+107]\n",
      "\tRtlClearBits [0x777BB6CF+191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scraping date\n",
    "try:\n",
    "    date = driver.find_element(By.CLASS_NAME,\"match-dates ng-binding\").text\n",
    "except NoSuchElementException as e:\n",
    "    print('Exception raised:',e)\n",
    "    date = driver.find_element(By.XPATH,'//div[@class=\"match-dates ng-binding\"]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ab8921b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7 JUN 2023'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed5d2a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception raised: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".match-time no-margin ng-binding\"}\n",
      "  (Session info: chrome=112.0.5615.138)\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\tGetHandleVerifier [0x0060DCE3+50899]\n",
      "\t(No symbol) [0x0059E111]\n",
      "\t(No symbol) [0x004A5588]\n",
      "\t(No symbol) [0x004D08F9]\n",
      "\t(No symbol) [0x004D0AFB]\n",
      "\t(No symbol) [0x004FF902]\n",
      "\t(No symbol) [0x004EB944]\n",
      "\t(No symbol) [0x004FE01C]\n",
      "\t(No symbol) [0x004EB6F6]\n",
      "\t(No symbol) [0x004C7708]\n",
      "\t(No symbol) [0x004C886D]\n",
      "\tGetHandleVerifier [0x00873EAE+2566302]\n",
      "\tGetHandleVerifier [0x008A92B1+2784417]\n",
      "\tGetHandleVerifier [0x008A327C+2759788]\n",
      "\tGetHandleVerifier [0x006A5740+672048]\n",
      "\t(No symbol) [0x005A8872]\n",
      "\t(No symbol) [0x005A41C8]\n",
      "\t(No symbol) [0x005A42AB]\n",
      "\t(No symbol) [0x005971B7]\n",
      "\tBaseThreadInitThunk [0x76C57D49+25]\n",
      "\tRtlInitializeExceptionChain [0x777BB74B+107]\n",
      "\tRtlClearBits [0x777BB6CF+191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scraping time\n",
    "try:\n",
    "    time = driver.find_element(By.CLASS_NAME,\"match-time no-margin ng-binding\").text\n",
    "except NoSuchElementException as e:\n",
    "    print('Exception raised:',e)\n",
    "    time = driver.find_element(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c013c5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3:30 PM IST'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a073cb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Match title': 'Final',\n",
       " 'Series': 'ICC WORLD TEST CHAMPIONSHIP FINAL 2023',\n",
       " 'Place': 'Kennington Oval, London',\n",
       " 'Date': '7 JUN 2023',\n",
       " 'Time': '3:30 PM IST'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary\n",
    "fixtures = {'Match title':match_title,'Series':series,'Place':place,'Date':date,'Time':time}\n",
    "fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d080d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fb09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4392f224",
   "metadata": {},
   "source": [
    "##### 3. Scrape the details of State-wise GDP of India from statisticstime.com.  \n",
    "Url = http://statisticstimes.com/                                                                      \n",
    "You have to find following details:                                                                                            \n",
    "A) Rank                                                                                                                    \n",
    "B) State                                                                                                                      \n",
    "C) GSDP(18-19)- at current prices                                                                                              \n",
    "D) GSDP(19-20)- at current prices                                                                                      \n",
    "E) Share(18-19)                                                                                                         \n",
    "F) GDP($ billion)                                                                                                      \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "785f1bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11ff54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"Z:\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "007cccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the page on automated chrome browser\n",
    "driver.get(\" http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5eeb2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fc7e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select economy\n",
    "economy = driver.find_elements(By.XPATH,'//div[@class=\"navbar\"]/div[2]')\n",
    "for i in economy:\n",
    "    eco = i.find_element(By.XPATH,\"button\")\n",
    "    eco.click()\n",
    "    \n",
    "    india = i.find_element(By.XPATH,\"div/a[3]\")\n",
    "    india.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6612e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing pop-up ads\n",
    "driver.switch_to.frame('aswift_2')                     # switch frame\n",
    "time.sleep(1)\n",
    "driver.switch_to.frame('ad_iframe')\n",
    "time.sleep(1)\n",
    "driver.find_element(By.ID,\"dismiss-button\").click()    # click on close button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59bd30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on GDP of Indian states\n",
    "GDP_india = driver.find_element(By.XPATH,'//a[@href=\"india/indian-states-gdp.php\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8387d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDP = []\n",
    "\n",
    "# scraping required data\n",
    "rows = driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr')\n",
    "for row in rows:\n",
    "    rank = row.find_element(By.XPATH,\"td[1]\").text                    # scraping rank\n",
    "    Rank.append(rank)\n",
    "    \n",
    "    state = row.find_element(By.XPATH,\"td[2]\").text                  # scraping state\n",
    "    State.append(state)\n",
    "    \n",
    "    gsdp1 = row.find_element(By.XPATH,\"td[3]\").text                 # scraping GSDP(19-20)\n",
    "    GSDP1.append(gsdp1)\n",
    "    \n",
    "    gsdp2 = row.find_element(By.XPATH,\"td[4]\").text                # scraping GSDP(18-19)\n",
    "    GSDP2.append(gsdp2)\n",
    "    \n",
    "    share = row.find_element(By.XPATH,\"td[5]\").text                # Scraping Share(18-19)\n",
    "    Share.append(share)\n",
    "    \n",
    "    gdp = row.find_element(By.XPATH,\"td[6]\").text                  # scraping GDP($billion)\n",
    "    GDP.append(gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1949569a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33 33 33 33\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(State),len(GSDP1),len(GSDP2),len(Share),len(GDP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23d8b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe\n",
    "GSDP = pd.DataFrame({\n",
    "    'Rank':Rank,\n",
    "    'State':State,\n",
    "    'GSDP(19-20) at current prices':GSDP1,\n",
    "    'GSDP(18-19) at current prices':GSDP2,\n",
    "    'Share(18-19)':Share,\n",
    "    'GDP($billion)':GDP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10b7d21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20) at current prices</th>\n",
       "      <th>GSDP(18-19) at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(19-20) at current prices  \\\n",
       "0     1                Maharashtra                             -   \n",
       "1     2                 Tamil Nadu                     1,845,853   \n",
       "2     3              Uttar Pradesh                     1,687,818   \n",
       "3     4                    Gujarat                             -   \n",
       "4     5                  Karnataka                     1,631,977   \n",
       "5     6                West Bengal                     1,253,832   \n",
       "6     7                  Rajasthan                     1,020,989   \n",
       "7     8             Andhra Pradesh                       972,782   \n",
       "8     9                  Telangana                       969,604   \n",
       "9    10             Madhya Pradesh                       906,672   \n",
       "10   11                     Kerala                             -   \n",
       "11   12                      Delhi                       856,112   \n",
       "12   13                    Haryana                       831,610   \n",
       "13   14                      Bihar                       611,804   \n",
       "14   15                     Punjab                       574,760   \n",
       "15   16                     Odisha                       521,275   \n",
       "16   17                      Assam                             -   \n",
       "17   18               Chhattisgarh                       329,180   \n",
       "18   19                  Jharkhand                       328,598   \n",
       "19   20                Uttarakhand                             -   \n",
       "20   21            Jammu & Kashmir                             -   \n",
       "21   22           Himachal Pradesh                       165,472   \n",
       "22   23                        Goa                        80,449   \n",
       "23   24                    Tripura                        55,984   \n",
       "24   25                 Chandigarh                             -   \n",
       "25   26                 Puducherry                        38,253   \n",
       "26   27                  Meghalaya                        36,572   \n",
       "27   28                     Sikkim                        32,496   \n",
       "28   29                    Manipur                        31,790   \n",
       "29   30                   Nagaland                             -   \n",
       "30   31          Arunachal Pradesh                             -   \n",
       "31   32                    Mizoram                        26,503   \n",
       "32   33  Andaman & Nicobar Islands                             -   \n",
       "\n",
       "   GSDP(18-19) at current prices Share(18-19) GDP($billion)  \n",
       "0                      2,632,792       13.94%       399.921  \n",
       "1                      1,630,208        8.63%       247.629  \n",
       "2                      1,584,764        8.39%       240.726  \n",
       "3                      1,502,899        7.96%       228.290  \n",
       "4                      1,493,127        7.91%       226.806  \n",
       "5                      1,089,898        5.77%       165.556  \n",
       "6                        942,586        4.99%       143.179  \n",
       "7                        862,957        4.57%       131.083  \n",
       "8                        861,031        4.56%       130.791  \n",
       "9                        809,592        4.29%       122.977  \n",
       "10                       781,653        4.14%       118.733  \n",
       "11                       774,870        4.10%       117.703  \n",
       "12                       734,163        3.89%       111.519  \n",
       "13                       530,363        2.81%        80.562  \n",
       "14                       526,376        2.79%        79.957  \n",
       "15                       487,805        2.58%        74.098  \n",
       "16                       315,881        1.67%        47.982  \n",
       "17                       304,063        1.61%        46.187  \n",
       "18                       297,204        1.57%        45.145  \n",
       "19                       245,895        1.30%        37.351  \n",
       "20                       155,956        0.83%        23.690  \n",
       "21                       153,845        0.81%        23.369  \n",
       "22                        73,170        0.39%        11.115  \n",
       "23                        49,845        0.26%         7.571  \n",
       "24                        42,114        0.22%         6.397  \n",
       "25                        34,433        0.18%         5.230  \n",
       "26                        33,481        0.18%         5.086  \n",
       "27                        28,723        0.15%         4.363  \n",
       "28                        27,870        0.15%         4.233  \n",
       "29                        27,283        0.14%         4.144  \n",
       "30                        24,603        0.13%         3.737  \n",
       "31                        22,287        0.12%         3.385  \n",
       "32                             -            -             -  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fadcc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af195725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e0ed12c",
   "metadata": {},
   "source": [
    "##### 4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/                                                                                                   \n",
    "You have to find the following details:                                                                                    \n",
    "A) Repository title                                                                                                      \n",
    "B) Repository description                                                                                                     \n",
    "C) Contributors count                                                                                                     \n",
    "D) Language used  \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0d7f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e360334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"Z:\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98432081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the page on automated chrome browser\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed19aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76ec740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on open source and trending option\n",
    "explore = driver.find_elements(By.XPATH,'//ul[@class=\"d-lg-flex list-style-none\"]/li[3]')\n",
    "for i in explore:\n",
    "    open_source = i.find_element(By.XPATH,\"button\")\n",
    "    open_source.click()\n",
    "    \n",
    "    trending = i.find_element(By.XPATH,\"div/div[3]/ul/li[2]/a\")\n",
    "    trending.click()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c4c98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "repo_title = []\n",
    "repo_des = []\n",
    "contributors = []\n",
    "language_used = []\n",
    "\n",
    "\n",
    "# scraping required data\n",
    "rows = driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]')\n",
    "for row in rows:\n",
    "    \n",
    "     # repository title\n",
    "    title = row.find_element(By.XPATH,'.//h2[@class=\"h3 lh-condensed\"]//a')\n",
    "    repo_title.append(title.text)\n",
    "    \n",
    "    # repository description    \n",
    "    try:\n",
    "        description = row.find_element(By.XPATH,'.//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "        repo_des.append(description.text)\n",
    "    except NoSuchElementException:\n",
    "        repo_des.append(\"-\")\n",
    "        \n",
    "    # contributors count\n",
    "    count = row.find_elements(By.XPATH,'.//span[@class=\"d-inline-block mr-3\"]/a')\n",
    "    contributors.append(len(count))\n",
    "    \n",
    "    # language used    \n",
    "    try:\n",
    "        language = row.find_element(By.XPATH,'.//span[@class=\"d-inline-block ml-0 mr-3\"]/span[2]')\n",
    "        language_used.append(language.text)\n",
    "    except NoSuchElementException:\n",
    "        language_used.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0f4a310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(repo_title),len(repo_des),len(contributors),len(language_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6572e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe\n",
    "trending_repo = pd.DataFrame({\n",
    "    'Repository title':repo_title,\n",
    "    'Repository description':repo_des,\n",
    "    'Contributors count':contributors,\n",
    "    'Language used':language_used\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f2d301c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xtekky / gpt4free</td>\n",
       "      <td>decentralising the Ai Industry, just some lang...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIGC-Audio / AudioGPT</td>\n",
       "      <td>AudioGPT: Understanding and Generating Speech,...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaomingqi / Track-Anything</td>\n",
       "      <td>Track-Anything is a flexible and interactive t...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eugeny / tabby</td>\n",
       "      <td>A terminal for a more modern age</td>\n",
       "      <td>5</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whoiskatrin / chart-gpt</td>\n",
       "      <td>AI tool to build charts based on text input</td>\n",
       "      <td>5</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apple / swift-foundation</td>\n",
       "      <td>The Foundation project</td>\n",
       "      <td>5</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gmpetrov / databerry</td>\n",
       "      <td>The no-code platform for connecting custom dat...</td>\n",
       "      <td>3</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deep-floyd / IF</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UX-Decoder / Segment-Everything-Everywhere-All...</td>\n",
       "      <td>Official implementation of the paper \"Segment ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nlpxucan / WizardLM</td>\n",
       "      <td>WizardLM: Empowering Large Pre-Trained Languag...</td>\n",
       "      <td>3</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>QiuChenly / QQFlacMusicDownloader</td>\n",
       "      <td>[秋城落叶] QQ 音乐源无损歌曲下载</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sindresorhus / awesome</td>\n",
       "      <td>😎 Awesome lists about all kinds of interesting...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ai-collection / ai-collection</td>\n",
       "      <td>The Generative AI Landscape - A Collection of ...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GreyDGL / PentestGPT</td>\n",
       "      <td>A GPT-empowered penetration testing tool</td>\n",
       "      <td>3</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>juspay / hyperswitch</td>\n",
       "      <td>An Open Source Financial Switch to make Paymen...</td>\n",
       "      <td>5</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Snaacky / dndserver</td>\n",
       "      <td>Dark and Darker private server implementation ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NVIDIA / NeMo-Guardrails</td>\n",
       "      <td>NeMo Guardrails is an open-source toolkit for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>farizrahman4u / loopgpt</td>\n",
       "      <td>Modular Auto-GPT Framework</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>litanlitudan / skyagi</td>\n",
       "      <td>SkyAGI: Emerging human-behavior simulation cap...</td>\n",
       "      <td>4</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>isaiahbjork / Auto-GPT-MetaTrader-Plugin</td>\n",
       "      <td>The AutoGPT MetaTrader Plugin is a software to...</td>\n",
       "      <td>2</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ZrrSkywalker / LLaMA-Adapter</td>\n",
       "      <td>Fine-tuning LLaMA to follow Instructions withi...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>agalwood / Motrix</td>\n",
       "      <td>A full-featured download manager.</td>\n",
       "      <td>5</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BigBrotherTrade / trader</td>\n",
       "      <td>交易模块</td>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0hq / WebGPT</td>\n",
       "      <td>Run GPT model on the browser with WebGPU. An i...</td>\n",
       "      <td>5</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>angular / angular</td>\n",
       "      <td>The modern web developer’s platform</td>\n",
       "      <td>5</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository title  \\\n",
       "0                                   xtekky / gpt4free   \n",
       "1                               AIGC-Audio / AudioGPT   \n",
       "2                          gaomingqi / Track-Anything   \n",
       "3                                      Eugeny / tabby   \n",
       "4                             whoiskatrin / chart-gpt   \n",
       "5                            apple / swift-foundation   \n",
       "6                                gmpetrov / databerry   \n",
       "7                                     deep-floyd / IF   \n",
       "8   UX-Decoder / Segment-Everything-Everywhere-All...   \n",
       "9                                 nlpxucan / WizardLM   \n",
       "10                  QiuChenly / QQFlacMusicDownloader   \n",
       "11                             sindresorhus / awesome   \n",
       "12                      ai-collection / ai-collection   \n",
       "13                               GreyDGL / PentestGPT   \n",
       "14                               juspay / hyperswitch   \n",
       "15                                Snaacky / dndserver   \n",
       "16                           NVIDIA / NeMo-Guardrails   \n",
       "17                            farizrahman4u / loopgpt   \n",
       "18                              litanlitudan / skyagi   \n",
       "19           isaiahbjork / Auto-GPT-MetaTrader-Plugin   \n",
       "20                       ZrrSkywalker / LLaMA-Adapter   \n",
       "21                                  agalwood / Motrix   \n",
       "22                           BigBrotherTrade / trader   \n",
       "23                                       0hq / WebGPT   \n",
       "24                                  angular / angular   \n",
       "\n",
       "                               Repository description  Contributors count  \\\n",
       "0   decentralising the Ai Industry, just some lang...                   5   \n",
       "1   AudioGPT: Understanding and Generating Speech,...                   5   \n",
       "2   Track-Anything is a flexible and interactive t...                   5   \n",
       "3                    A terminal for a more modern age                   5   \n",
       "4         AI tool to build charts based on text input                   5   \n",
       "5                              The Foundation project                   5   \n",
       "6   The no-code platform for connecting custom dat...                   3   \n",
       "7                                                   -                   5   \n",
       "8   Official implementation of the paper \"Segment ...                   5   \n",
       "9   WizardLM: Empowering Large Pre-Trained Languag...                   3   \n",
       "10                                [秋城落叶] QQ 音乐源无损歌曲下载                   5   \n",
       "11  😎 Awesome lists about all kinds of interesting...                   5   \n",
       "12  The Generative AI Landscape - A Collection of ...                   5   \n",
       "13           A GPT-empowered penetration testing tool                   3   \n",
       "14  An Open Source Financial Switch to make Paymen...                   5   \n",
       "15  Dark and Darker private server implementation ...                   5   \n",
       "16  NeMo Guardrails is an open-source toolkit for ...                   1   \n",
       "17                         Modular Auto-GPT Framework                   5   \n",
       "18  SkyAGI: Emerging human-behavior simulation cap...                   4   \n",
       "19  The AutoGPT MetaTrader Plugin is a software to...                   2   \n",
       "20  Fine-tuning LLaMA to follow Instructions withi...                   5   \n",
       "21                  A full-featured download manager.                   5   \n",
       "22                                               交易模块                   1   \n",
       "23  Run GPT model on the browser with WebGPU. An i...                   5   \n",
       "24                The modern web developer’s platform                   5   \n",
       "\n",
       "   Language used  \n",
       "0         Python  \n",
       "1         Python  \n",
       "2         Python  \n",
       "3     TypeScript  \n",
       "4     TypeScript  \n",
       "5          Swift  \n",
       "6     TypeScript  \n",
       "7         Python  \n",
       "8         Python  \n",
       "9         Python  \n",
       "10        Python  \n",
       "11             -  \n",
       "12             -  \n",
       "13          HTML  \n",
       "14          Rust  \n",
       "15        Python  \n",
       "16        Python  \n",
       "17        Python  \n",
       "18        Python  \n",
       "19        Python  \n",
       "20        Python  \n",
       "21    JavaScript  \n",
       "22        Python  \n",
       "23    JavaScript  \n",
       "24    TypeScript  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c7583c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40f15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "445bc925",
   "metadata": {},
   "source": [
    "##### 5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/                                                                                              \n",
    "You have to find the following details:                                                                                      \n",
    "A) Song name                                                                                                                 \n",
    "B) Artist name                                                                                                               \n",
    "C) Last week rank                                                                                                           \n",
    "D) Peak rank                                                                                                                  \n",
    "E) Weeks on board                                                                                                              \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "609c99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21ca9dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"Z:\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "782d9d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the page on automated chrome browser\n",
    "driver.get(\"https:/www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5c8fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd4a7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on charts\n",
    "chart = driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]')\n",
    "chart.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb0f8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on Billboard Hot 100\n",
    "hot_100 = driver.find_element(By.XPATH,'//div[@class=\"u-flex-grow-0 lrv-u-text-align-center\"]')\n",
    "hot_100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "406947a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "song_name = []\n",
    "artist_name = []\n",
    "last_week_rank = []\n",
    "peak_rank = []\n",
    "weeks_on_chart = []\n",
    "\n",
    "# scraping required data\n",
    "\n",
    "rows = driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul')\n",
    "for r in rows:\n",
    "    \n",
    "    element = r.find_elements(By.XPATH,\"li[1]\")\n",
    "    for ele in element:\n",
    "        song = ele.find_element(By.XPATH,\"h3\").text                      # scraping song name\n",
    "        song_name.append(song)\n",
    "        \n",
    "        artist = ele.find_element(By.XPATH,\"span\").text                  # scraping artist name\n",
    "        artist_name.append(artist)\n",
    "    \n",
    "    last = r.find_element(By.XPATH,\"li[4]\").text                        # scraping last week rank\n",
    "    last_week_rank.append(last)\n",
    "    \n",
    "    peak = r.find_element(By.XPATH,\"li[5]\").text                        # scraping peak rank\n",
    "    peak_rank.append(peak)\n",
    "    \n",
    "    weeks = r.find_element(By.XPATH,\"li[6]\").text                       # scraping weeks on chart\n",
    "    weeks_on_chart.append(weeks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64dc9a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(song_name),len(artist_name),len(last_week_rank),len(peak_rank),len(weeks_on_chart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cef11c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe\n",
    "Top_100_songs = pd.DataFrame({\n",
    "    'Song name':song_name,\n",
    "    'Artist name':artist_name,\n",
    "    'Last week rank':last_week_rank,\n",
    "    'Peak rank':peak_rank,\n",
    "    'Weeks on board':weeks_on_chart\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0a5abbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Princess Diana</td>\n",
       "      <td>Ice Spice &amp; Nicki Minaj</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ella Baila Sola</td>\n",
       "      <td>Eslabon Armado X Peso Pluma</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Memory Lane</td>\n",
       "      <td>Old Dominion</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Love Again</td>\n",
       "      <td>The Kid LAROI</td>\n",
       "      <td>88</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>'98 Braves</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Di Que Si</td>\n",
       "      <td>Grupo Marca Registrada X Grupo Frontera</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>It Matters To Her</td>\n",
       "      <td>Scotty McCreery</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Song name                              Artist name Last week rank  \\\n",
       "0           Kill Bill                                      SZA              4   \n",
       "1          Last Night                            Morgan Wallen              1   \n",
       "2             Flowers                              Miley Cyrus              3   \n",
       "3      Princess Diana                  Ice Spice & Nicki Minaj              -   \n",
       "4     Ella Baila Sola              Eslabon Armado X Peso Pluma             10   \n",
       "..                ...                                      ...            ...   \n",
       "95        Memory Lane                             Old Dominion             96   \n",
       "96         Love Again                            The Kid LAROI             88   \n",
       "97         '98 Braves                            Morgan Wallen            100   \n",
       "98          Di Que Si  Grupo Marca Registrada X Grupo Frontera              -   \n",
       "99  It Matters To Her                          Scotty McCreery              -   \n",
       "\n",
       "   Peak rank Weeks on board  \n",
       "0          1             19  \n",
       "1          1             12  \n",
       "2          1             14  \n",
       "3          4              1  \n",
       "4          5              5  \n",
       "..       ...            ...  \n",
       "95        96              3  \n",
       "96        40             12  \n",
       "97        27              7  \n",
       "98        99              1  \n",
       "99       100              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_100_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a215ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45e888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7711bd0",
   "metadata": {},
   "source": [
    "##### 6. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare              \n",
    "You have to find the following details:                                                                                      \n",
    "A) Book name                                                                                                               \n",
    "B) Author name                                                                                                                \n",
    "C) Volumes sold                                                                                                             \n",
    "D) Publisher                                                                                                                 \n",
    "E) Genre                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01e50fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf3ff12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"Z:\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48677bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the page on automated chrome browser\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba6c0844",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc6fb85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "book_name = []\n",
    "author_name = []\n",
    "volumes_sold = []\n",
    "publisher = []\n",
    "genre = []\n",
    "\n",
    "# scraping required data\n",
    "rows = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr')\n",
    "\n",
    "for r in rows:\n",
    "    book = r.find_element(By.XPATH,\"td[2]\").text                      # scraping book name\n",
    "    book_name.append(book)\n",
    "    \n",
    "    author = r.find_element(By.XPATH,\"td[3]\").text                   # scraping author name\n",
    "    author_name.append(author)\n",
    "    \n",
    "    volumes = r.find_element(By.XPATH,\"td[4]\").text                 # scraping volumes sold\n",
    "    volumes_sold.append(volumes)\n",
    "    \n",
    "    pub = r.find_element(By.XPATH,\"td[5]\").text                     # scraping publisher\n",
    "    publisher.append(pub)\n",
    "    \n",
    "    gen = r.find_element(By.XPATH,\"td[6]\").text                     # scraping genre\n",
    "    genre.append(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efb345de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(book_name),len(author_name),len(volumes_sold),len(publisher),len(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b801b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe\n",
    "Books = pd.DataFrame({\n",
    "    'Book name':book_name,\n",
    "    'Author name':author_name,\n",
    "    'Vloumes sold':volumes_sold,\n",
    "    'Publisher':publisher,\n",
    "    'Genre':genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12ebb8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Vloumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Vloumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58a545af",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fdd38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f311542a",
   "metadata": {},
   "source": [
    "###### 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/                                                                                \n",
    "You have to find the following details:                                                                                        \n",
    "A) Name                                                                                                                       \n",
    "B) Year span                                                                                                                   \n",
    "C) Genre                                                                                                                    \n",
    "D) Run time                                                                                                                   \n",
    "E) Ratings                                                                                                                   \n",
    "F) Votes                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55698845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd02b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send GET request\n",
    "\n",
    "page = requests.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "495a3963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking response code\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8d6d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page content\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59918704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "Name = []\n",
    "year = []\n",
    "genre = []\n",
    "run_time = []\n",
    "ratings = []\n",
    "votes = []\n",
    "\n",
    "# scraping required data\n",
    "\n",
    "name_year = soup.find_all('h3', class_=\"lister-item-header\")\n",
    "for i in name_year:\n",
    "    Name.append(i.text.split('\\n')[2])                        # scraping name\n",
    "    year.append(i.text.split('\\n')[3])                        # scraping year span\n",
    "    \n",
    "gen = soup.find_all('span',class_=\"genre\")                    # scraping genre\n",
    "for g in gen:\n",
    "    genre.append(g.text.strip())\n",
    "    \n",
    "time = soup.find_all('span',class_=\"runtime\")                       # scraping time\n",
    "for t in time:\n",
    "    run_time.append(t.text)\n",
    "    \n",
    "rating = soup.find_all('div',class_=\"ipl-rating-star small\")       # scraping time\n",
    "for j in rating:\n",
    "    ratings.append(j.text.strip())\n",
    "    \n",
    "vote = soup.find_all(attrs={\"name\":\"nv\"})                          # scraping votes\n",
    "for v in vote:\n",
    "    votes.append(v.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d52b3fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(year),len(genre),len(run_time),len(ratings),len(votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4cbf120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe\n",
    "TV_series = pd.DataFrame({'Name':Name,'Year span':year,'Genre':genre,'Run time':run_time,'Ratings':ratings,'Votes':votes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c86a6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,154,408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,236,266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,023,467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>301,149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>260,115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63,465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>206,930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>42,974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>256,618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98                          Scream  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,154,408  \n",
       "1    51 min     8.7  1,236,266  \n",
       "2    44 min     8.1  1,023,467  \n",
       "3    60 min     7.5    301,149  \n",
       "4    43 min     7.6    260,115  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     51,430  \n",
       "96   50 min     7.8     63,465  \n",
       "97   42 min     8.1    206,930  \n",
       "98   45 min       7     42,974  \n",
       "99  572 min     8.6    256,618  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TV_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a522f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feec7408",
   "metadata": {},
   "source": [
    "##### 8. Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/                                                                                           \n",
    "You have to find the following details:                                                                                      \n",
    "A) Dataset name                                                                                                            \n",
    "B) Data type                                                                                                             \n",
    "C) Task                                                                                                                     \n",
    "D) Attribute type                                                                                                          \n",
    "E) No of instances                                                                                                           \n",
    "F) No of attribute                                                                                                          \n",
    "G) Year                                                                                                                       \n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "358a5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da027335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"Z:\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "21fae640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the page on automated chrome browser\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f3270ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4be90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on view all data sets\n",
    "show_all = driver.find_element(By.TAG_NAME,\"b\")\n",
    "show_all.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5969a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "dataset_name = []\n",
    "data_type = []\n",
    "task = []\n",
    "attribute_type = []\n",
    "no_of_instances = []\n",
    "no_of_attribute = []\n",
    "year = []\n",
    "\n",
    "\n",
    "# scraping dataset name\n",
    "name = driver.find_elements(By.XPATH,'//p[@class=\"normal\"]/b')\n",
    "for i in name:\n",
    "    try:\n",
    "        dataset_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        dataset_name.append(\"-\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# scraping required data\n",
    "rows = driver.find_elements(By.XPATH,\"//table[2]/tbody/tr/td[2]/table[2]/tbody/tr\")\n",
    "\n",
    "for r in rows[1:623]:\n",
    "    \n",
    "    try:\n",
    "        types = r.find_element(By.XPATH,\"td[2]\").text                # scraping data type\n",
    "        if types == ' ':\n",
    "            data_type.append(\"-\")\n",
    "        else:\n",
    "            data_type.append(types)\n",
    "    except NoSuchElementException:\n",
    "        data_type.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        task1 = r.find_element(By.XPATH,\"td[3]\").text               # scraping task\n",
    "        if task1 == ' ':\n",
    "            task.append(\"-\")\n",
    "        else:\n",
    "            task.append(task1)\n",
    "    except NoSuchElementException:\n",
    "        task.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        attr_type = r.find_element(By.XPATH,\"td[4]\").text          # scraping attribute type\n",
    "        if attr_type == ' ':\n",
    "            attribute_type.append(\"-\")\n",
    "        else:\n",
    "            attribute_type.append(attr_type)\n",
    "    except NoSuchElementException:\n",
    "        attribute_type.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        instance = r.find_element(By.XPATH,\"td[5]\").text          # scraping no. of instances\n",
    "        if instance == ' ':\n",
    "            no_of_instances.append(\"-\")\n",
    "        else:\n",
    "            no_of_instances.append(instance)\n",
    "    except NoSuchElementException:\n",
    "        no_of_instances(\"-\")\n",
    "        \n",
    "    try:\n",
    "        attr_no = r.find_element(By.XPATH,\"td[6]\").text          # scraping no. of attribute\n",
    "        if attr_no == ' ':\n",
    "            no_of_attribute.append(\"-\")\n",
    "        else:\n",
    "            no_of_attribute.append(attr_no)\n",
    "    except NoSuchElementException:\n",
    "        no_of_attribute.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        yrs = r.find_element(By.XPATH,\"td[7]\").text             # scraping years\n",
    "        if yrs == ' ':\n",
    "            year.append(\"-\")\n",
    "        else:\n",
    "            year.append(yrs)\n",
    "    except NoSuchElementException:\n",
    "        year.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5eadc695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 622 622 622 622 622 622\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_name),len(data_type),len(task),len(attribute_type),len(no_of_instances),len(no_of_attribute),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "91551be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe\n",
    "Datasets = pd.DataFrame({\n",
    "    'Dataset name':dataset_name,\n",
    "    'Data type':data_type,\n",
    "    'Task':task,\n",
    "    'Attribute type':attribute_type,\n",
    "    'No. of instances':no_of_instances,\n",
    "    'No. of attribute':no_of_attribute,\n",
    "    'Year':year,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "49c74d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No. of instances</th>\n",
       "      <th>No. of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>-</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                             -  Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                           -       Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute type No. of instances No. of attribute   Year  \n",
       "0    Categorical, Integer, Real             4177                8   1995   \n",
       "1          Categorical, Integer            48842               14   1996   \n",
       "2    Categorical, Integer, Real              798               38       -  \n",
       "3                   Categorical            37711              294   1998   \n",
       "4    Categorical, Integer, Real              452              279   1998   \n",
       "..                           ...              ...              ...    ...  \n",
       "617               Integer, Real            75840              525   2020   \n",
       "618               Integer, Real              400               50   2020   \n",
       "619                            -            1014                7   2020   \n",
       "620                        Real            10129               16   2021   \n",
       "621                        Real             4000                2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d88a480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647c77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edcf9b92",
   "metadata": {},
   "source": [
    "##### 9. Scrape the details of Data science recruiters    \n",
    "Url = https://www.naukri.com/hr-recruiters-consultants                                                                      \n",
    "You have to find the following details:                                                                                       \n",
    "A) Name                                                                                                                    \n",
    "B) Designation                                                                                                            \n",
    "C) Company                                                                                                                \n",
    "D) Skills they hire for                                                                                           \n",
    "E) Location                                                                                                                 \n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b9e3e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cadb0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"Z:\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3540d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/hr-recruiters-consultants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "712e989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "34cbcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter designation in search bar\n",
    "search_bar = driver.find_element(By.NAME,\"qp\")\n",
    "search_bar.send_keys('Data science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "56d6b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on search button\n",
    "search_button = driver.find_element(By.ID,\"qsbFormBtn\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "030ce895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "name = []\n",
    "designation = []\n",
    "company = []\n",
    "skills = []\n",
    "location = []\n",
    "\n",
    "# page limit\n",
    "start = 0\n",
    "end = 10\n",
    "\n",
    "# scraping required data\n",
    "for page in range(start,end):\n",
    "    \n",
    "    rows = driver.find_elements(By.XPATH,'//div[@class=\"recInfo\"]')\n",
    "    for row in rows:\n",
    "        # name\n",
    "        try:\n",
    "            name_tag = row.find_element(By.XPATH,'.//span[@class=\"fl ellipsis\"]').text\n",
    "            name.append(name_tag)\n",
    "        except NoSuchElementException:\n",
    "            name.append(\"-\")\n",
    "        \n",
    "        # designation\n",
    "        try:\n",
    "            designation_tag = row.find_element(By.XPATH,'.//span[@class=\"ellipsis clr\"]').text\n",
    "            designation.append(designation_tag)\n",
    "        except NoSuchElementException:\n",
    "            designation.append(\"-\")\n",
    "        \n",
    "        # company\n",
    "        try:\n",
    "            comp = row.find_element(By.XPATH,'.//p[@class=\"highlightable\"]/a[2]').text\n",
    "            company.append(comp)\n",
    "        except NoSuchElementException:\n",
    "            company.append(\"-\")\n",
    "        \n",
    "        # skills\n",
    "        try:\n",
    "            skill = row.find_element(By.XPATH,'div[2]').text\n",
    "            skills.append(skill)\n",
    "        except NoSuchElementException:\n",
    "            skills.append(\"-\")\n",
    "        \n",
    "        # location\n",
    "        try:\n",
    "            loc = row.find_element(By.XPATH,'.//small[@class=\"ellipsis\"]').text\n",
    "            location.append(loc)\n",
    "        except NoSuchElementException:\n",
    "            location.append(\"-\")\n",
    "            \n",
    "    time.sleep(5)\n",
    "    NEXT = driver.find_element(By.XPATH,\"//*[text()='Next']\").click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6877ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500 500 500 500\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(designation),len(company),len(skills),len(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38352635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe\n",
    "Recruiters_info = pd.DataFrame({\n",
    "    'Name':name,\n",
    "    'Designation':designation,\n",
    "    'Company':company,\n",
    "    'Skills':skills,\n",
    "    'Location':location\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8880f2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Naveen Raina</td>\n",
       "      <td>Director</td>\n",
       "      <td>CLICKVALLEY</td>\n",
       "      <td>html5, css, javascript, angularjs, asp.net mvc...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Ritvvij Parrikh</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Pykih Data Intelligence Private Limited</td>\n",
       "      <td>Javascript, React.js, Data Science, Machine Le...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Birendra Bisht</td>\n",
       "      <td>Founder and CEO</td>\n",
       "      <td>Intello Transpo Private Limited</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Neha</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>Dreamz Consultants</td>\n",
       "      <td>Software Development, Scrum Master, Supply Cha...</td>\n",
       "      <td>Ernakulam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Bhagyashree Chandak</td>\n",
       "      <td>Talent Acquisition Manager</td>\n",
       "      <td>phData</td>\n",
       "      <td>Javascript, Scala, Python, Spark, Cloudera, Hi...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name                 Designation  \\\n",
       "0                Aakash Harit                  HR Manager   \n",
       "1        shravan Kumar Gaddam           Company Recruiter   \n",
       "2    MARSIAN Technologies LLP                  Company HR   \n",
       "3                Anik Agrawal           Company Recruiter   \n",
       "4                subhas patel                 Founder CEO   \n",
       "..                        ...                         ...   \n",
       "495              Naveen Raina                    Director   \n",
       "496           Ritvvij Parrikh                         CEO   \n",
       "497            Birendra Bisht             Founder and CEO   \n",
       "498                      Neha      Recruitment Consultant   \n",
       "499       Bhagyashree Chandak  Talent Acquisition Manager   \n",
       "\n",
       "                                     Company  \\\n",
       "0                       Data Science Network   \n",
       "1              Shore Infotech India Pvt. Ltd   \n",
       "2                   MARSIAN Technologies LLP   \n",
       "3      Enerlytics Software Solutions Pvt Ltd   \n",
       "4                            LibraryXProject   \n",
       "..                                       ...   \n",
       "495                              CLICKVALLEY   \n",
       "496  Pykih Data Intelligence Private Limited   \n",
       "497          Intello Transpo Private Limited   \n",
       "498                       Dreamz Consultants   \n",
       "499                                   phData   \n",
       "\n",
       "                                                Skills  \\\n",
       "0    Classic ASP Developer, Internet Marketing Prof...   \n",
       "1    .Net, Java, Data Science, Linux Administration...   \n",
       "2    Data Science, Artificial Intelligence, Machine...   \n",
       "3    Mean Stack, javascript, angularjs, mongodb, We...   \n",
       "4    Hadoop, Spark, Digital Strategy, Data Architec...   \n",
       "..                                                 ...   \n",
       "495  html5, css, javascript, angularjs, asp.net mvc...   \n",
       "496  Javascript, React.js, Data Science, Machine Le...   \n",
       "497                                      Not Specified   \n",
       "498  Software Development, Scrum Master, Supply Cha...   \n",
       "499  Javascript, Scala, Python, Spark, Cloudera, Hi...   \n",
       "\n",
       "                     Location  \n",
       "0                       Delhi  \n",
       "1    Hyderabad / Secunderabad  \n",
       "2                        Pune  \n",
       "3                   Ahmedabad  \n",
       "4               UK - (london)  \n",
       "..                        ...  \n",
       "495                     Delhi  \n",
       "496                    Mumbai  \n",
       "497                     Delhi  \n",
       "498                 Ernakulam  \n",
       "499     Bengaluru / Bangalore  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recruiters_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d4772ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c1947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
